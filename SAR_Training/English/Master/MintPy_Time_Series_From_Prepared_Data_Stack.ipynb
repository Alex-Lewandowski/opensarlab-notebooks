{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hideOutput": true
   },
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.png\" width=\"100%\" />\n",
    "\n",
    "# InSAR Time Series Analysis using MintPy and HyP3 products\n",
    "\n",
    "**Author:** Alex Lewandowski; University of Alaska Fairbanks\n",
    "\n",
    "Based on the [LosAngeles_time_series](https://github.com/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Hazards/LosAngeles_time_series.ipynb) notebook by Eric Fielding, David Bekaert, Heresh Fattahi and Zhang Yunjun, which uses an example ARIA dataset.\n",
    "\n",
    "\n",
    "\n",
    "## Mapping surface deformation with InSAR time series\n",
    "\n",
    "This notebook demonstrates how to create an InSAR time series with MintPy using an ASF HyP3 InSAR data stack, which can be ordered on [ASF Data Search/Vertex](https://search.asf.alaska.edu/#/) and prepared using the [Prepare_HyP3_InSAR_Stack_for_MintPy](https://github.com/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/Prepare_HyP3_InSAR_Stack_for_MintPy.ipynb) notebook.\n",
    "\n",
    "<img src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" />\n",
    "\n",
    "It also explores how to assess the quality of the stack inversion, temporal coherence, and velocity errors.\n",
    "\n",
    "**Important Note about JupyterHub**\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%%javascript\n",
    "var kernel = Jupyter.notebook.kernel;\n",
    "var command = [\"notebookUrl = \",\n",
    "               \"'\", window.location, \"'\" ].join('')\n",
    "kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/insar_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"insar_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select \"insar_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"insar_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: Notebook setup\n",
    "\n",
    "**Import necessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import h5py\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import mintpy.view\n",
    "import mintpy.tsview\n",
    "import mintpy.plot_network\n",
    "import mintpy.plot_transection\n",
    "import mintpy.plot_coherence_matrix\n",
    "import mintpy.objects.insar_vs_gps\n",
    "import mintpy.utils\n",
    "\n",
    "import asf_notebook as asfn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the directory holding your MintPy-ready HyP3 data stack**\n",
    "- Click the `Select` button\n",
    "- Navigate to your data directory\n",
    "- Click the `Select` button\n",
    "- Confirm that the desired path appears in green text\n",
    "- Click the `Change` button to alter your selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser('/home/jovyan/notebooks')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a project name and create a MintPy directory in which to store files output during our analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the work directory\n",
    "work_path = Path(fc.selected_path)\n",
    "print(f\"Work directory: {work_path}\")\n",
    "\n",
    "# define a project name\n",
    "proj_name = input(\"Enter a project name: \")\n",
    "\n",
    "# define the MintPy time-series directory\n",
    "mint_path = work_path/'MintPy'\n",
    "if not mint_path.is_dir():\n",
    "    mint_path.mkdir()\n",
    "print(f\"MintPy directory: {mint_path}\")\n",
    "\n",
    "#create a directory in which to store plots\n",
    "plot_path = mint_path/\"plots\"\n",
    "if not plot_path.is_dir():\n",
    "    plot_path.mkdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def work_dir(work_pth):\n",
    "  cwd = Path.cwd()\n",
    "  os.chdir(work_pth)\n",
    "  try:\n",
    "      yield\n",
    "  finally:\n",
    "      os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Add Your Climate Data Store (CDS) UID & API Key to the Pyaps3 Config \n",
    "\n",
    "### This step only needs to be completed once and may be skipped if you have already updated the config for your conda environment\n",
    "\n",
    "- Running the MintPy smallbaselineApp's `correct_troposphere` step requires downloading atmospheric pressure data from the CDS\n",
    "- If don't yet have a CDS API key:\n",
    "    - Proceed to [CDS](https://cds.climate.copernicus.eu/cdsapp#!/home) and create an account\n",
    "    - Open the [Datasets page](https://cds.climate.copernicus.eu/cdsapp#!/search?type=dataset)\n",
    "    - Search for \"ERA5\"\n",
    "    - Select any of ERA5 datasets that appear\n",
    "    - Select the `Download data` tab\n",
    "    - Scroll to the bottom of the screen\n",
    "    - Accept the `Terms of use`\n",
    "    - Click on your name at the top right of the screen to access your profile page\n",
    "    - Your `UID` and `API Key` will be displayed here \n",
    "- Open an OpenSARlab terminal\n",
    "- Use vim or another text editor to open the `model.cfg` config file in your `insar_analysis` conda environment's `pyaps3` directory\n",
    "    - If you built the `insar_analysis` environment using the Create_OSL_Conda_Environments.ipynb notebook, it will be located here:\n",
    "        - `~/.local/envs/insar_analysis/lib/python3.8/site-packages/pyaps3/model.cfg`\n",
    "    - Add your `UID` and `API Key` to the `[CDS]` profile in the config\n",
    "        - This should be formatted like:\n",
    "            - `key = <UID>:<API Key>`\n",
    "    - Save the config and exit the text editor\n",
    "\n",
    "**If you do not add your CDS credentials to `model.cfg`, the `correct_troposphere` step will fail**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. smallbaselineApp.py overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This application provides a workflow which includes several steps to invert a stack of unwrapped interferograms and apply different corrections to obtain ground displacement timeseries.  \n",
    "The workflow consists of two main blocks:\n",
    "\n",
    "* correcting unwrapping errors and inverting for the raw phase time-series (blue ovals),\n",
    "* correcting for noise from different sources to obtain the displacement time-series (green ovals).\n",
    "\n",
    "Some steps are optional, which are switched off by default (marked by dashed boundaries). Configuration parameters for each step are initiated with default values in a customizable text file: [smallbaselineApp.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp.cfg). In this notebook, we will walk through some of these steps, for a complete example see the [MintPy repository](https://github.com/insarlab/MintPy).\n",
    "\n",
    "<p align=\"left\">\n",
    "  <img width=\"600\" src=\"../Hazards/NotebookAddons/MintPyWorkflow.jpg\">\n",
    "</p>     \n",
    "<p style=\"text-align: center;\">\n",
    "    (Figure from Yunjun et al., 2019)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Processing steps of smallbaselineApp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MintPy **smallbaselineApp.py** application provides a workflow to invert a stack of unwrapped interferograms and apply different (often optional) corrections to obtain ground displacement timeseries. A detailed overview of the options can be retrieved by involking the help option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Configuring processing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing parameters for the **smallbaselineApp.py** are controlled through a configuration file. If no file is provided the default [smallbaselineApp.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp.cfg) configuration is used. We will create a custom config file with modified configuration parameters for this time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f'''# vim: set filetype=cfg:\n",
    "mintpy.load.processor        = hyp3\n",
    "##---------interferogram datasets:\n",
    "mintpy.load.unwFile          = {work_path}/*/*unw_phase_clip.tif\n",
    "mintpy.load.corFile          = {work_path}/*/*corr_clip.tif\n",
    "##---------geometry datasets:\n",
    "mintpy.load.demFile          = {work_path}/*/*dem_clip.tif\n",
    "mintpy.load.incAngleFile     = {work_path}/*/*lv_theta_clip.tif\n",
    "mintpy.load.azAngleFile      = {work_path}/*/*lv_phi_clip.tif\n",
    "mintpy.load.waterMaskFile    = {work_path}/*/*water_mask_clip.tif\n",
    "'''\n",
    "\n",
    "config_path = mint_path/f'{proj_name}.txt'\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config)\n",
    "    print(f\"config file path: {config_path}\\n\")\n",
    "    \n",
    "with open(config_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Small Baseline Time Series Analysis\n",
    "\n",
    "**You can run every step in smallbaselineApp.py with one call, using the command in the cell below**\n",
    "\n",
    "**For the purposes of this tutorial, we will run each step separately**\n",
    "\n",
    "We will run the steps:\n",
    "- load_data\n",
    "- modify_network\n",
    "- reference_point\n",
    "- quick_overview\n",
    "- invert_network\n",
    "- correct_troposphere\n",
    "- correct_topography\n",
    "- residual_RMS\n",
    "- reference_date\n",
    "- velocity\n",
    "- google_earth\n",
    "\n",
    "Skipped steps include:\n",
    "- correct_unwrap_error\n",
    "- correct_LOD\n",
    "- correct_SET\n",
    "- deramp\n",
    "- hdfeos5\n",
    "\n",
    "Skipped steps will also be skipped if running the entire smallbaselineApp in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This runs every step\n",
    "\n",
    "# !smallbaselineApp.py --work-dir {mint_path}  {config_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Load Data\n",
    "\n",
    "**Run the `load_data` step**\n",
    "\n",
    "- If you get a missing 'Height' attribute error, you are missing a DEM, which is an available option when ordering HyP3 InSAR products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the loading step is an \"inputs\" directory containing two HDF5 files:\n",
    "- ifgramStack.h5: This file contains 6 dataset cubes (e.g. unwrapped phase, coherence, connected components etc.) and multiple metadata.  \n",
    "- geometryGeo.h5: This file contains geometrical datasets (e.g., incidence/azimuth angle, masks, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_path = mint_path/'inputs'\n",
    "!ls $inputs_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>info.py :</b> \n",
    "To get general infomation about a MintPy product, run info.py on the file.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!info.py $inputs_path/ifgramStack.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Modify the Network\n",
    "\n",
    "**Run the `modify_network` step**\n",
    "\n",
    "- If a water mask was provided, this step generates waterMask.h5\n",
    "- Modify the network based on temporal/perpendicular baselines, date, num of connections etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep modify_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Plot the interferogram network\n",
    "\n",
    "Running **plot_network.py** gives an overview of the network and the average coherence of the stack. The program creates multiple files as follows:\n",
    "- ifgramStack_coherence_spatialAvg.txt: Contains interferogram dates, average coherence temporal and spatial baseline separation.\n",
    "- Network.pdf: Displays the network of interferograms on time-baseline coordinates, colorcoded by avergae coherence of the interferograms. \n",
    "- CoherenceMatrix.pdf shows the avergae coherence pairs between all available pairs in the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "with work_dir(mint_path):\n",
    "    mintpy.plot_network.main([f'{inputs_path}/ifgramStack.h5'])\n",
    "    plots = ['bperpHistory.pdf', 'coherenceHistory.pdf', 'coherenceMatrix.pdf', 'network.pdf']\n",
    "    for p in plots:\n",
    "        if (mint_path/p).exists():\n",
    "            (mint_path/p).rename(f'{plot_path}/{p}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Set the Reference Point\n",
    "\n",
    "**Run the `reference_point` step**\n",
    "\n",
    "The interferometric phase is a relative observation by nature. The phases of each unwrapped interferogram are relative with respect to an arbitrary pixel. Therfore, we need to reference all interferograms to a common reference pixel.\n",
    "\n",
    "The `reference_point` step selects a common reference pixel for the stack of interferograms. The default approach of MintPy is to choose a pixel with the highest spatial coherence in the stack. Other options include specifying the longitude and latitude of the desired reference pixel or the line and column number of the refence pixel.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep reference_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the \"reference_step\" adds additional attributes \"REF_X, REF_Y\" and \"REF_LON, REF_LAT\" to the ifgramStack.h5 file. To see the attributes of the file run info.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py $inputs_path/ifgramStack.h5 | egrep 'REF_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Run a Quick Overview\n",
    "\n",
    "**Run the `quick_overview` step**\n",
    "\n",
    "- Assess possible groud deformation using the velocity from traditional interferogram stacking \n",
    "    - *reference: Zebker et al. (1997, JGR)*\n",
    "- Assess distribution of phase unwrapping error from the number of interferogram triplets with non-zero integer ambiguity of closure phase \n",
    "    - *reference: T_int in Yunjun et al. (2019, CAGEO). Related to section 3.2, equation (8-9) and Fig. 3d-e.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep quick_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Inverting the Small Baseline network\n",
    "\n",
    "**Run the `invert_network` step**\n",
    "\n",
    "- Invert the network of differential unwrapped interferograms to estimate the time-series of unwrapped phase with respect to a reference acquisition date\n",
    "- By default mintpy selects the first acquisition\n",
    "- The estimated time-series is converted to distance change from radar to target and is provided in meters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep invert_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7. Correct for Tropospheric Propagation Delays\n",
    "\n",
    "**Run the `correct_troposphere` step**\n",
    "\n",
    "- Uses ECMWF [ERA5 climate reanalysis pressure data](https://cds.climate.copernicus.eu/cdsapp#!/search?type=dataset&keywords=((%20%22Product%20type:%20Reanalysis%22%20)%20AND%20(%20%22Provider:%20Copernicus%20C3S%22%20))&text=pressure)\n",
    "- CDS limits ECMWF archive requests to 50, so your requests may be queued until there is space.\n",
    "    - https://cds.climate.copernicus.eu/live/queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep correct_troposphere "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8. Correct for DEM Errors\n",
    "\n",
    "**Run the `correct_topography` step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep correct_topography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the corrected, inverted time series steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_args = f'{mint_path}/timeseries_ERA5_demErr.h5 --wrap --wrap-range -15 15 --notitle --notick --noaxis --dpi 600 --figsize 15 15 --outfile {plot_path}/inverted_ts.png'\n",
    "mintpy.view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9. Calculate the Root Mean Square (RMS) of Residual Phase Time-Series for Each Acquisition\n",
    "\n",
    "**Run the `residual_RMS` step**\n",
    "\n",
    "- *reference: Yunjun et al. (2019, section 4.9 and 5.4)*\n",
    "- To remove the long wavelength component in space, a phase ramp is removed for each acquisition\n",
    "- Sets optimal reference date to date with min RMS\n",
    "- Sets exclude dates (outliers) to dates with RMS > cutoff * median RMS (Median Absolute Deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep residual_RMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10. Reference the Entire Time-Series to One Date in Time\n",
    "\n",
    "**Run the `reference_date` step**\n",
    "\n",
    "- *reference: Yunjun et al. (2019, section 4.9)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep reference_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11. Estimate The Long-Term Velocity Rate\n",
    "\n",
    "**Run the `velocity` step**\n",
    "\n",
    "The timeseries file contains three datasets:\n",
    "- the `time-series` dataset, which is the interferometric range change for each acquisition relative to the reference acquisition\n",
    "- the `date` dataset, which contains the acquisition date for each acquisition\n",
    "- the `bperp` dataset, which contains the timeseries of the perpendicular baseline \n",
    "\n",
    "The ground deformation caused by many geophysical or anthropogenic processes are linear at first order approximation. Therefore it is common to estimate the rate of the ground deformation which is the slope of linear fit to the time-series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_args = f'{mint_path}/velocity.h5 velocity -v -1 1 --dpi 600 --figsize 15 15 --outfile {plot_path}/velocity.png'\n",
    "mintpy.view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Note :</b> \n",
    "Negative values indicates that target is moving away from the radar (i.e., Subsidence in case of vertical deformation).\n",
    "Positive values indicates that target is moving towards the radar (i.e., uplift in case of vertical deformation). \n",
    "    The line of sight (LOS) for this descending Sentinel-1 track is up and east from ground to radar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12. Geocode velocity.h5 in Preparation for Creating a velocity.kmz\n",
    "\n",
    "**Run the `geocode` step**\n",
    "\n",
    "- This is unnecessary for geocoded HyP3 data but would be needed for non-geocoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep geocode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13. Create a kmz File\n",
    "\n",
    "**Run the `google_earth` step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py $config_path --work-dir {mint_path} --dostep google_earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Error analysis (signal vs noise)\n",
    "\n",
    "Uncertainty of the ground displacement products derived from InSAR time-series, depends on the quality of the inversion of the stack of interferograms and the accuracy in separating the ground displacement from other components of the InSAR data. Therefore the definition of signal vs noise is different at the two main steps in MintPy:  \n",
    "\n",
    "1) During the inversion: \n",
    "    At this step all systematic components of the interferometric phase (e.g., ground displacement, propagation delay, geometrical residuals caused by DEM or platform's orbit inaccuracy) are considered signal, while the interferometric phase decorrelation, phase unwrapping error and phase inconsistency are considered noise. \n",
    "    \n",
    "2) After inversion: the ground displacement component of the time-serieses is signal, and everything else (including the propagation delay and geometrical residuals) are considered noise\n",
    "\n",
    "Therefore we first discuss the possible sources of error during the inversion and the existing ways in MintPy to evaluate the quality of inversion and to improve the uncertainty of the inversion. Afterwards we explain the different components of the time-series and the different processing steps in MintPy to separate them from ground displacement signal.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Quality of the inversion\n",
    "\n",
    "The main sources of noise during the time-series inversion includes decorrelation, phase unwrapping error and the inconsistency of triplets of interferofgrams. Here we mainly focus on the decorrelation and unwrapping errors. We first show the existing quantities in MintPy to evaluate decorrelation and unwrapping errors and then discuss the existing ways in MintPy to reduce the decorrelation and unwrapping errors on the time-series inversion.\n",
    "\n",
    "### 4.1.1. Average spatial coherence\n",
    "\n",
    "Mintpy computes temporal average of spatial coherence of the entire stack as a potential ancillary measure to choose reliable pixels after time-series inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "scp_args = f\"{mint_path}/avgSpatialCoh.h5 --dpi 600 --figsize 15 15 --outfile {plot_path}/avg_spatial_coh.png\"\n",
    "mintpy.view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Temporal coherence\n",
    "\n",
    "In addition to timeseries.h5 which contains the time-series dataset, invert_network produces other quantities, which contain metrics to evaluate the quality of the inversion including temporalCoherence.h5. Temporal coherence represents the consistency of the timeseries with the network of interferograms. \n",
    "\n",
    "Temporal coherence varies from 0 to 1. Pixels with values closer to 1 are considered reliable and pixels with values closer to zero are considered unreliable. For a dense network of interferograms, a threshold of 0.7 may be used (Yunjun et al, 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "scp_args = f\"{mint_path}/temporalCoherence.h5 --dpi 600 --figsize 15 15 --outfile {plot_path}/temporal_coh.png\"\n",
    "mintpy.view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Velocity error analysis\n",
    "\n",
    "The estimated velocity also comes with an expression of unecrtainty which is simply based on the goodness of fit while fitting a linear model to the time-series. This quantity is saved in \"velocity.h5\" under the velocityStd dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "scp_args = f'{mint_path}/velocity.h5 velocityStd -v 0 0.2 --dpi 600 --figsize 15 15 --outfile {plot_path}/velocity_err.png'\n",
    "mintpy.view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the plot above is the velocity error, not the velocity. The errors generally increase with distance from the reference point and also increase for points with elevations different from the reference point because of topographically correlated water vapor variations that are especially strong in this area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Compare InSAR time-series with GPS time-series in LOS direction\n",
    "\n",
    "- http://geodesy.unr.edu/NGLStationPages/gpsnetmap/GPSNetMap.html\n",
    "- http://geodesy.unr.edu/NGLStationPages/DataHoldings.txt\n",
    "\n",
    "### 4.3.1. Identify Potential GPS stations\n",
    "\n",
    "**Write the University of Nevada, Reno GPS station holdings metadata to GPS_stations.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with work_dir(mint_path):\n",
    "    url = 'http://geodesy.unr.edu/NGLStationPages/DataHoldings.txt'\n",
    "    response = urllib.request.urlopen(url, timeout=5)\n",
    "    content = response.read()\n",
    "    rows = content.decode('utf-8').splitlines()\n",
    "    holdings_txt = Path('.')/'DataHoldings.txt'\n",
    "    if holdings_txt.exists():\n",
    "        holdings_txt.unlink()\n",
    "\n",
    "with open(f'{mint_path}/GPS_stations.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',', escapechar=',', quoting=csv.QUOTE_NONE)\n",
    "    for row in rows:\n",
    "        csv_writer.writerow([re.sub('\\s+', ' ', row)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a list of GPS stations within your area of interest and select one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the InSAR stack's corner coordinates\n",
    "with h5py.File(f\"{mint_path}/inputs/geometryGeo.h5\", 'r') as f:\n",
    "    lon_west = float(f.attrs['LON_REF1'])\n",
    "    lon_east = float(f.attrs['LON_REF2'])\n",
    "    lat_south = float(f.attrs['LAT_REF1'])\n",
    "    lat_north = float(f.attrs['LAT_REF3'])\n",
    "\n",
    "# get the start and end dates of the timeseries\n",
    "info = gdal.Info(f\"{mint_path}/timeseries_ERA5_demErr.h5\", format='json')\n",
    "ts_start = info['metadata']['']['START_DATE']\n",
    "ts_start = datetime.strptime(ts_start, '%Y%m%d')\n",
    "ts_end = info['metadata']['']['END_DATE']\n",
    "ts_end = datetime.strptime(ts_end, '%Y%m%d')\n",
    "\n",
    "# find all stations that have data within the ts time range,\n",
    "# are located within the AOI and at an unmasked pixel location\n",
    "gps_stations = list()\n",
    "with open(f'{mint_path}/GPS_stations.csv', newline='') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in list(csv_reader)[1:]:\n",
    "        begin_date = datetime.strptime(row[7], '%Y-%m-%d')\n",
    "        mod_date = datetime.strptime(row[9], '%Y-%m-%d')\n",
    "        lat = float(row[1])\n",
    "        if float(row[2]) > 180:\n",
    "            lon = float(row[2]) - 360\n",
    "        else:\n",
    "            lon = float(row[2])\n",
    "\n",
    "        n = [lat, lon]\n",
    "        a = [lat_north, lon_west]\n",
    "        b = [lat_south, lon_west]\n",
    "        c = [lat_south, lon_east]\n",
    "        ab = np.subtract(a, b)\n",
    "        an = np.subtract(a, n)\n",
    "        bc = np.subtract(b, c)\n",
    "        bn = np.subtract(b, n)\n",
    "\n",
    "        in_aoi = 0 <= np.dot(ab, an) <= np.dot(ab, ab) and 0 <= np.dot(bc, bn) <= np.dot(bc, bc)\n",
    "        in_date_range = ts_start >= begin_date and ts_end <= mod_date\n",
    "        \n",
    "        if in_aoi and in_date_range:\n",
    "            vel_file = f'{mint_path}/velocity.h5'\n",
    "            atr = mintpy.utils.readfile.read_attribute(vel_file)\n",
    "            coord = mintpy.utils.utils.coordinate(atr, lookup_file=f'{mint_path}/inputs/geometryRadar.h5')\n",
    "            y, x = coord.geo2radar(lat, lon)[:2]\n",
    "            msk = mintpy.utils.readfile.read(f'{mint_path}/maskTempCoh.h5')[0]\n",
    "            box = (x, y, x+1, y+1)\n",
    "            masked = not msk[y, x]\n",
    "            if not masked:\n",
    "                gps_stations.append(row[0].strip())\n",
    "                \n",
    "if len(gps_stations) > 0:\n",
    "    gps_station = asfn.select_parameter(gps_stations)\n",
    "    print(\"Select a GPS station\")\n",
    "    display(gps_station)\n",
    "else:\n",
    "    print(\"No GPS stations found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "scp_args = f\"{mint_path}/velocity.h5 velocity --show-gps --ref-gps {gps_station.value} --gps-comp enu2los --gps-label --figsize 9 9\"\n",
    "with work_dir(mint_path):\n",
    "    mintpy.view.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with work_dir(plot_path):\n",
    "    mintpy.objects.insar_vs_gps.plot_insar_vs_gps_scatter(vel_file=f'{mint_path}/velocity.h5',\n",
    "                              ref_gps_site=gps_station.value,\n",
    "                              csv_file=f'{mint_path}/gps_enu2los.csv',\n",
    "                              msk_file=f'{mint_path}/maskTempCoh.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Plotting a Motion Transect \n",
    "\n",
    "**Select the transect to plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "image_file = f\"{mint_path}/temporalCoherence.h5\"\n",
    "img = gdal.Open(image_file)\n",
    "rasterstack = img.ReadAsArray()\n",
    "\n",
    "line = asfn.LineSelector(rasterstack, 9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = list(work_path.glob('*/*_amp_clip.tif'))[0]\n",
    "amp = gdal.Open(str(amp))\n",
    "geotrans = amp.GetGeoTransform()\n",
    "\n",
    "def geolocation(x, y, geotrans):\n",
    "    return [geotrans[0]+x*geotrans[1], geotrans[3]+y*geotrans[5]]\n",
    "\n",
    "try:\n",
    "    pnt_1 = geolocation(line.pnt1[0][0], line.pnt1[0][1], geotrans)\n",
    "    pnt_2 = geolocation(line.pnt2[0][0], line.pnt2[0][1], geotrans)\n",
    "    print(f\"point 1: {pnt_1}\")\n",
    "    print(f\"point 2: {pnt_2}\")\n",
    "except TypeError:\n",
    "    print('TypeError')\n",
    "    display(Markdown(f'<text style=color:red>This error may occur if a line was not selected.</text>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "scp_args = f'{mint_path}/velocity.h5 --start-lalo {pnt_1[1]} {pnt_1[0]} --end-lalo {pnt_2[1]} {pnt_2[0]} --outfile x'\n",
    "with work_dir(plot_path):\n",
    "    mintpy.plot_transection.main(scp_args.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Plot the Cumulative Displacement Map and Point Displacement Time Series\n",
    "\n",
    "- Use the `Time` bar below the Cumulative Displacement Map to view displacements for different time periods\n",
    "- Click on the Cumulative Displacement Map to select points for displaying Point Displacement Time-Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "mintpy.tsview.main([f'{mint_path}/timeseries.h5', f'-d={mint_path}/inputs/geometryGeo.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mintpy reference: *Yunjun, Z., H. Fattahi, F. Amelung (2019), Small baseline InSAR time series analysis: unwrapping error correction and noise reduction, preprint doi:[10.31223/osf.io/9sz6m](https://eartharxiv.org/9sz6m/).*\n",
    "\n",
    "- University of Miami online time-series viewer: https://insarmaps.miami.edu/\n",
    "\n",
    "- Mintpy Github repository: https://github.com/insarlab/MintPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>MintPy_Time_Series_From_Prepared_Data_Stack.ipynb - Version 0.1 - September 2021\n",
    "<br>\n",
    "</i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insar_analysis [conda env:.local-insar_analysis]",
   "language": "python",
   "name": "conda-env-.local-insar_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
