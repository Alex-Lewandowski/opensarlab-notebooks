{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.png\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Prepare a SAR Data Stack</b><img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Joseph H Kennedy and Alex Lewandowski; Alaska Satellite Facility </b> <br>\n",
    "</font>\n",
    "\n",
    "<font size=\"3\"> This notebook downloads an ASF-HyP3 RTC project and prepares a deep multi-temporal SAR image data stack for use in other notebooks.</font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color=\"darkred\"> <b>Important Note about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%javascript\n",
    "var kernel = Jupyter.notebook.kernel;\n",
    "var command = [\"notebookUrl = \",\n",
    "               \"'\", window.location, \"'\" ].join('')\n",
    "kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 0. Importing Relevant Python Packages </b> </font>\n",
    "\n",
    "<font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "</font>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Our first step is to import them:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import copy\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import json # for loads\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "\n",
    "import asf_notebook as asfn\n",
    "\n",
    "from hyp3_sdk import Batch, HyP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 1. Load Your Own Data Stack Into the Notebook </b> </font>\n",
    "\n",
    "<font size=\"3\"> This notebook assumes that you've created your own data stack over your personal area of interest using the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility's</a> value-added product system HyP3, available via <a href=\"https://search.asf.alaska.edu/#/\" target=\"_blank\">ASF Data Search (Vertex)</a>. HyP3 is an ASF service used to prototype value added products and provide them to users to collect feedback.\n",
    "\n",
    "We will retrieve HyP3 data via the hyp3_sdk. As both HyP3 and the Notebook environment sit in the <a href=\"https://aws.amazon.com/\" target=\"_blank\">Amazon Web Services (AWS)</a> cloud, data transfer is quick and cost effective.</font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> Before we download anything, create a working directory for this analysis.\n",
    "<br><br>\n",
    "<b>Select or create a working directory for the analysis:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    data_dir = Path(asfn.input_path(f\"\\nPlease enter the name of a directory in which to store your data for this analysis.\"))\n",
    "    if data_dir == Path('.'):\n",
    "        continue\n",
    "    if data_dir.is_dir():\n",
    "        contents = data_dir.glob('*')\n",
    "        if len(list(contents)) > 0:\n",
    "            choice = asfn.handle_old_data(data_dir, list(contents))\n",
    "            if choice == 1:\n",
    "                if data_dir.exists():\n",
    "                    shutil.rmtree(data_dir)\n",
    "                data_dir.mkdir()\n",
    "                break\n",
    "            elif choice == 2:\n",
    "                break\n",
    "            else:\n",
    "                clear_output()\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        data_dir.mkdir()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Define absolute path to  analysis directory:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_directory = Path.cwd().joinpath(data_dir)\n",
    "print(f\"analysis_directory: {analysis_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a HyP3 object and authenticate</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyp3 = HyP3(prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select a product type to download:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_types = ['RTC_GAMMA', 'INSAR_GAMMA', 'AUTORIFT']\n",
    "job_type = asfn.select_parameter(job_types)\n",
    "job_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decide whether to search for a HyP3 project or jobs unattached to a project** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['project', 'projectless jobs']\n",
    "search_type = asfn.select_parameter(options, '')\n",
    "print(\"Select whether to search for HyP3 Project or HyP3 Jobs unattached to a project\")\n",
    "display(search_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>List projects containing active products of the type chosen in the previous cell and select one:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hyp3_info = hyp3.my_info()\n",
    "active_projects = dict()\n",
    "\n",
    "if search_type.value == 'project':\n",
    "    for project in my_hyp3_info['job_names']:\n",
    "        batch = Batch()\n",
    "        batch = hyp3.find_jobs(name=project, job_type=job_type.value).filter_jobs(running=False, include_expired=False)\n",
    "        if len(batch) > 0:\n",
    "            active_projects.update({batch.jobs[0].name: batch})\n",
    "\n",
    "    if len(active_projects) > 0:\n",
    "        display(Markdown(\"<text style='color:darkred;'>Note: After selecting a project, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "        display(Markdown(\"<text style='color:darkred;'>Otherwise, you will rerun this code cell.</text>\"))\n",
    "        print('\\nSelect a Project:')\n",
    "        project_select = asfn.select_parameter(active_projects)\n",
    "        display(project_select)\n",
    "if search_type.value == 'projectless jobs' or len(active_projects) == 0:\n",
    "    project_select = False\n",
    "    if search_type.value == 'project':\n",
    "        print(f\"There were no {job_type.value} jobs found in any current projects.\\n\")\n",
    "    jobs = hyp3.find_jobs(job_type=job_type.value).filter_jobs(running=False, include_expired=False)\n",
    "    orphaned_jobs = Batch()\n",
    "    for j in jobs:\n",
    "        if not j.name:\n",
    "            orphaned_jobs += j\n",
    "    jobs = orphaned_jobs\n",
    "\n",
    "    if len(jobs) > 0:\n",
    "        print(f\"Found {len(jobs)} {job_type.value} jobs that are not part of a project.\")\n",
    "        print(f\"Select the jobs you wish to download\")\n",
    "        jobs = {i.files[0]['filename']: i for i in jobs}\n",
    "        jobs_select = asfn.select_mult_parameters(jobs, '', width='500px')\n",
    "        display(jobs_select)\n",
    "    else:\n",
    "        print(f\"There were no {job_type.value} jobs found that are not part of a project either.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select a date range of products to download:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if project_select:\n",
    "    batch = project_select.value\n",
    "else:\n",
    "    batch = Batch()\n",
    "    for j in jobs_select.value:\n",
    "        batch += j\n",
    "\n",
    "display(Markdown(\"<text style='color:darkred;'>Note: After selecting a date range, you should select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "display(Markdown(\"<text style='color:darkred;'>Otherwise, you may simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Date Range:')\n",
    "dates = asfn.get_job_dates(batch)\n",
    "date_picker = asfn.gui_date_picker(dates)\n",
    "date_picker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected date range and remove products falling outside of it:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_range = asfn.get_slider_vals(date_picker)\n",
    "date_range[0] = date_range[0].date()\n",
    "date_range[1] = date_range[1].date()\n",
    "print(f\"Date Range: {str(date_range[0])} to {str(date_range[1])}\")\n",
    "batch = asfn.filter_jobs_by_date(batch, date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Gather the available paths and orbit directions for the remaining products:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"<text style='color:darkred;'><text style='font-size:150%;'>This may take some time for projects containing many jobs...</text></text>\"))\n",
    "batch = asfn.get_paths_orbits(batch)\n",
    "paths = set()\n",
    "orbit_directions = set()\n",
    "for p in batch:\n",
    "    paths.add(p.path)\n",
    "    orbit_directions.add(p.orbit_direction)\n",
    "paths.add('All Paths')\n",
    "display(Markdown(f\"<text style=color:blue><text style='font-size:175%;'>Done.</text></text>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Select a path or paths (use shift or ctrl to select multiple paths):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"<text style='color:darkred;'>Note: After selecting a path, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "display(Markdown(\"<text style='color:darkred;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Path:')\n",
    "path_choice = asfn.select_mult_parameters(paths)\n",
    "path_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected flight path/s:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_path = path_choice.value\n",
    "if flight_path:\n",
    "    if flight_path:\n",
    "        print(f\"Flight Path: {flight_path}\")\n",
    "    else:\n",
    "        print('Flight Path: All Paths')\n",
    "else:\n",
    "    print(\"WARNING: You must select a flight path in the previous cell, then rerun this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select an orbit direction:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(orbit_directions) > 1:\n",
    "    display(Markdown(\"<text style='color:red;'>Note: After selecting a flight direction, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "    display(Markdown(\"<text style='color:red;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Flight Direction:')\n",
    "direction_choice = asfn.select_parameter(orbit_directions, 'Direction:')\n",
    "direction_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected orbit direction:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = direction_choice.value\n",
    "print(f\"Orbit Direction: {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Filter jobs by path and orbit direction:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = asfn.filter_jobs_by_path(batch, flight_path)\n",
    "batch = asfn.filter_jobs_by_orbit(batch, direction)\n",
    "print(f\"There are {len(batch)} products to download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Download the products, unzip them into a directory named after the product type, and delete the zip files:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products_path = analysis_directory.joinpath(job_type.value)\n",
    "if not products_path.is_dir():\n",
    "    products_path.mkdir()\n",
    "\n",
    "print(f\"\\nProject: {batch.jobs[0].name}\")\n",
    "project_zips = batch.download_files(products_path)\n",
    "for z in project_zips:\n",
    "    asfn.asf_unzip(str(products_path), str(z))\n",
    "    z.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Determine the available polarizations if downloading RTC products:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc = batch.jobs[0].job_type == 'RTC_GAMMA'\n",
    "insar = batch.jobs[0].job_type == 'INSAR_GAMMA'\n",
    "autorift = batch.jobs[0].job_type == 'AUTORIFT'\n",
    "if rtc:\n",
    "    polarizations = asfn.get_RTC_polarizations(str(products_path))\n",
    "    polarization_power_set = asfn.get_power_set(polarizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select a polarization:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rtc:\n",
    "    polarization_choice = asfn.select_parameter(sorted(polarization_power_set), 'Polarizations:')\n",
    "else:\n",
    "    polarization_choice = None\n",
    "polarization_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a paths variable, holding the relative path to the tiffs or NetCDFs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rtc:\n",
    "    polarization = polarization_choice.value\n",
    "    print(polarization)\n",
    "    if len(polarization) == 2:\n",
    "        regex = \"\\w[\\--~]{{5,300}}(_|-){}.(tif|tiff)$\".format(polarization)\n",
    "        dbl_polar = False\n",
    "    else:\n",
    "        regex = \"\\w[\\--~]{{5,300}}(_|-){}(v|V|h|H).(tif|tiff)$\".format(polarization[0])\n",
    "        dbl_polar = True\n",
    "elif insar:\n",
    "    regex = \"\\w*_ueF_\\w*.tif$\"\n",
    "elif autorift:\n",
    "    regex = \"\\w*ASF_OD.nc$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write functions to collect and print the paths of the tiffs or NetCDFs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_paths(regex, pths):\n",
    "    product_paths = list()\n",
    "    paths = Path().glob(pths)\n",
    "    for pth in paths:\n",
    "        tiff_path = re.search(regex, str(pth))\n",
    "        if tiff_path:\n",
    "            product_paths.append(pth)\n",
    "    return product_paths\n",
    "\n",
    "def print_product_paths(product_paths):\n",
    "    print(\"Tiff paths:\")\n",
    "    for p in product_paths:\n",
    "        print(f\"{p}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write a function to collect the product acquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(product_paths):\n",
    "    dates = []\n",
    "    for pth in product_paths:\n",
    "        dates.append(asfn.date_from_product_name(str(pth)).split('T')[0])\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Collect and print the paths of the tiffs or NetCDFs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_prod_path = products_path.relative_to(Path.cwd())\n",
    "if rtc:\n",
    "    product_pth = f\"{str(rel_prod_path)}/*/*{polarization[0]}*.tif*\"\n",
    "elif insar:\n",
    "    product_pth = f\"{str(rel_prod_path)}/*/*.tif*\"\n",
    "elif autorift:\n",
    "    product_pth = f\"{str(rel_prod_path)}/*\"\n",
    "    \n",
    "    \n",
    "product_paths = get_product_paths(regex, product_pth)\n",
    "\n",
    "print_product_paths(product_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b>1.2 Fix multiple UTM Zone-related issues</b> <br>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Fix multiple UTM Zone-related issues should they exist in your data set. If multiple UTM zones are found, the following code cells will identify the predominant UTM zone and reproject the rest into that zone. This step must be completed prior to merging frames or performing any analysis. AutoRIFT products do not come with projection metadata and so will not be reprojected.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Use gdal.Info to determine the UTM definition types and zones in each product:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not autorift:\n",
    "    coord_choice = asfn.select_parameter([\"UTM\", \"Lat/Long\"], description='Coord Systems:')\n",
    "    coord_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not autorift:\n",
    "    utm_zones = []\n",
    "    utm_types = []\n",
    "    print('Checking UTM Zones in the data stack ...\\n')\n",
    "    for k in range(0, len(product_paths)):\n",
    "        info = (gdal.Info(str(product_paths[k]), options = ['-json']))\n",
    "        info = json.dumps(info)\n",
    "        info = (json.loads(info))['coordinateSystem']['wkt']\n",
    "        zone = info.split('ID')[-1].split(',')[1][0:-2]\n",
    "        utm_zones.append(zone)\n",
    "        typ = info.split('ID')[-1].split('\"')[1]\n",
    "        utm_types.append(typ)\n",
    "    print(f\"UTM Zones:\\n {utm_zones}\\n\")\n",
    "    print(f\"UTM Types:\\n {utm_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Identify the most commonly used UTM Zone in the data:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not autorift:\n",
    "    if coord_choice.value == 'UTM':\n",
    "        utm_unique, counts = np.unique(utm_zones, return_counts=True)\n",
    "        a = np.where(counts == np.max(counts))\n",
    "        predominant_utm = utm_unique[a][0]\n",
    "        print(f\"Predominant UTM Zone: {predominant_utm}\")\n",
    "    else:\n",
    "        predominant_utm = '4326'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Reproject all tiffs to the predominate UTM:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not autorift:\n",
    "    # Reproject (if needed) and Mosaic DEM Files in Preparation for Subsequent HAND Calculation\n",
    "    # print(DEM_paths)\n",
    "    reproject_indicies = [i for i, j in enumerate(utm_zones) if j != predominant_utm] #makes list of indicies in utm_zones that need to be reprojected\n",
    "    print('--------------------------------------------')\n",
    "    print('Reprojecting %4.1f files' %(len(reproject_indicies)))\n",
    "    print('--------------------------------------------')\n",
    "    for k in reproject_indicies:\n",
    "        temppath = f\"{str(product_paths[k].parent)}/r{product_paths[k].name}\"\n",
    "        print(temppath)  \n",
    "\n",
    "        cmd = f\"gdalwarp -overwrite {product_paths[k]} {temppath} -s_srs {utm_types[k]}:{utm_zones[k]} -t_srs EPSG:{predominant_utm}\"\n",
    "    #     print(cmd)\n",
    "        !{cmd}\n",
    "\n",
    "        product_paths[k].unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Update product_paths with any new filenames created during reprojection:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_paths = get_product_paths(regex, product_pth)\n",
    "print_product_paths(product_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b>1.3 Merge multiple frames from the same date.</b></font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> You may notice duplicates in your acquisition dates. As HyP3 processes SAR data on a frame-by-frame basis, duplicates may occur if your area of interest is covered by two consecutive image frames. In this case, two separate images are generated that need to be merged together before time series processing can commence. Currently we only merge RTCs.\n",
    "<br><br>\n",
    "<b>Create a directory in which to store the reprojected and merged RTCs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not autorift:\n",
    "    output_dir_path = analysis_directory.joinpath(f\"{job_type.value}_tiffs\")\n",
    "    print(output_dir_path)\n",
    "    if not output_dir_path.is_dir():\n",
    "        output_dir_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a set from the date list, removing any duplicates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rtc:\n",
    "    dates = get_dates(product_paths)\n",
    "    print(dates)\n",
    "    unique_dates = set(dates)\n",
    "    print(unique_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Determine which dates have multiple frames. Create a dictionary with each date as a key linked to a value set as an empty string:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rtc: \n",
    "    dup_date_batches = [{}]\n",
    "    for date in unique_dates:\n",
    "        count = 0\n",
    "        for d in dates:\n",
    "            if date == d:\n",
    "                count +=1\n",
    "        if (dbl_polar and count > 2) or (not dbl_polar and count > 1):\n",
    "            dup_date_batches[0].update({date : \"\"})\n",
    "    if dbl_polar:\n",
    "        dup_date_batches.append(copy.deepcopy(dup_date_batches[0]))\n",
    "    print(dup_date_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Update the key values in dup_paths with the string paths to all the tiffs for each date:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rtc:\n",
    "    if dbl_polar:\n",
    "        polar_list = [polarization.split(' ')[0], polarization.split(' ')[2]]\n",
    "    else:\n",
    "        polar_list = [polarization]\n",
    "\n",
    "    for i, polar in enumerate(polar_list):\n",
    "        polar_path_regex = f\"(\\w|/)*_{polar}.(tif|tiff)$\"\n",
    "        polar_paths = get_product_paths(polar_path_regex, product_pth)\n",
    "        for pth in polar_paths:\n",
    "            date = asfn.date_from_product_name(str(pth)).split('T')[0]\n",
    "            if date in dup_date_batches[i]:\n",
    "                dup_date_batches[i][date] = f\"{dup_date_batches[i][date]} {str(pth)}\"\n",
    "\n",
    "    for d in dup_date_batches:\n",
    "        print(d)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Merge all the frames for each date, save the results to the output directory, and delete the original tiffs.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rtc and len(dup_date_batches[0]) > 0:\n",
    "    for i, dup_dates in enumerate(dup_date_batches):\n",
    "        polar_regex = \"(?<=_)(vh|VH|vv|VV)(?=.tif{1,2})\"\n",
    "        polar = re.search(polar_regex, dup_dates[list(dup_dates)[0]])\n",
    "        if polar:\n",
    "            polar = f'_{polar.group(0)}'\n",
    "        else:\n",
    "            polar = ''\n",
    "        for dup_date in dup_dates:\n",
    "#             print(f\"\\n\\n{dup_dates[dup_date]}\")\n",
    "            output = f\"{str(output_dir_path)}/merged_{dup_date}T999999{polar}{product_paths[0].suffix}\"\n",
    "            gdal_command = f\"gdal_merge.py -o {output} {dup_dates[dup_date]}\"\n",
    "            print(f\"\\n\\nCalling the command: {gdal_command}\\n\")\n",
    "            !$gdal_command\n",
    "            for pth in dup_dates[dup_date].split(' '):\n",
    "                path = Path(pth)\n",
    "                if path and path.is_file():\n",
    "                    path.unlink()\n",
    "                    print(f\"Deleting: {str(pth)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Verify that all duplicate dates were resolved:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rtc:\n",
    "    product_paths = get_product_paths(regex, product_pth)\n",
    "    for polar in polar_list:\n",
    "        polar_product_pth = product_pth.replace('V*', polar)\n",
    "        polar_product_paths = get_product_paths(regex, polar_product_pth)\n",
    "        dates = get_dates(polar_product_paths)\n",
    "        if len(dates) != len(set(dates)):\n",
    "            print(f\"Duplicate dates still present!\")\n",
    "        else:\n",
    "            print(f\"No duplicate dates are associated with {polar} polarization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the updated the paths to all remaining non-merged tiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_product_paths(product_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Move all remaining unmerged tiffs into the output directory, and choose whether to save or delete the directory holding the remaining downloaded product files. AutoRIFT NetCDFs will remain in their original directory:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not autorift:\n",
    "    choices = ['save', 'delete']\n",
    "    print(\"Do you wish to save or delete the directory containing auxiliary product files?\")\n",
    "else:\n",
    "    choices = []\n",
    "save_or_del = asfn.select_parameter(choices)\n",
    "save_or_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not autorift:\n",
    "    for tiff in product_paths:\n",
    "        tiff.rename(f\"{output_dir_path}/{tiff.name}\")\n",
    "    if save_or_del.value == 'delete':\n",
    "        shutil.rmtree(products_path)\n",
    "    product_paths = get_product_paths(regex, product_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the path where you saved your tiffs or NetCDFs.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rtc or insar:\n",
    "    print(str(output_dir_path))\n",
    "elif autorift:\n",
    "    print(str(products_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Prepare_RTC_Stack_HyP3_v2.ipynb - Version 1.3.1 - October 2021\n",
    "    <br>\n",
    "    <b>Version Changes</b>\n",
    "    <ul>\n",
    "        <li>Identify and download jobs not belonging to a project</li>\n",
    "    </ul>\n",
    "    </i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis [conda env:.local-rtc_analysis]",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
